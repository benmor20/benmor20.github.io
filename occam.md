# OCCaM Lab

In the summer of 2021, I worked at the Olin College Crowdsourcing and Machine-Learning (OCCaM) Lab with advisor Paul Ruvolo. OCCaM Lab focuses on co-designing apps with and for the blind and visually impaired (B/VI) community. Their major one is Clew, with which users can walk somewhere with the aide of a sighted guide, then, using computer vision (largely empowered by Apple's ARKit), Clew can guide them back without the help of another person. The goal is to help provide a feeling of autonomy and independence without replacing the tried and true walking stick that the B/VI community relies on.

My specific work that summer was on a new app called Invisible Map. The goal of Invisible Map was to expand on Clew to allow for complete navigation of a building without the need for a sighted guide at all. We accomplished this by first creating a map of a space (done one time by, say, an employee there), and then allowing each user to download the building's map and naviagte with it as they would with Clew. Except, instead of merely retracing steps, Invisible Map would have the entire building's layout loaded and availble for use.

## My Work

When I joined OCCaM, Invisible Map was not a viable project. At its core, the plotting of a space is a Simultaneous Localization and Mapping (SLAM) problem, a common problem in the robotics space. When creating a map, the app must make the map and figure out where it is in the map *at the same time*. The main problem with this was drift; if sensors were perfect, this would be an easy problem. In reality, they tend to drift overtime - errors compound and the software's best guess of its location becomes less and less accurate. To fix this, previous Invisible Map developers decided to include April Tags around the building, to allow the algorithm to readjust itself when revisiting a tag. They hoped that this, plus [Generic Graph Optimization (G2O)](https://ieeexplore.ieee.org/document/5979949), would be enough to account for error in the sensors.

Unfortunately, it was not, and the result would be wildly skewed maps, with points many meters from where they should be, crazy angles, and the like. This is the state I entered the Invisible Map project. Over the course of the summer, my research partner and I narrowed down the source of the problem to two possible sources: bad weighting of the different error sources, or poor detection of the April Tags. We tackled both of these issues in parallel.

### Weighting Error

G2O is an amazing tool to solve SLAM problems, except that there is still some guesswork to be done: the weighing of the error sources. Since most SLAM problems are in 3-D environments, the error sources are $x$, $y$, $z$, *yaw*, *pitch*, and *roll* for each type of detection (for which we had two). This results in 12 separate weights that we had to tune, with no real way of knowing if the weights were good besides visually assessing at the resultant map. We spent some time implementing a genetic algorithm to calculate these weights, but with a lack of ground truth data, it was hard to find what the genetic algorithm should optimize towards.

Previous work had been done in OCCaM Lab to determine weights without ground truth data by comparing different weights against a standard set of weights. However, we found that what precisely this standard set of weights was had a significant impact on the ranking of the candidate weights, which just kicked the can down the line. More thorough investigation found that this difference largely came from different magnitudes of the weight vector, and adding the additional step of normalizing the standard weights to 1 would solve the issue.

### April Tag Detection

The other avenue we tackled was the detection of April Tags. April Tag Detection through a phone camera, while great in general, would occasionally have large outliers that greatly affected the quality of the map. It proved difficult to determine what these outliers were, and, since they largely were in relation to the orientation of the April Tag, they had the affect of essentially rotating the entire map, making for a large amount of error even just a few meters from the tag.

Our solution to this problem was to harness the power of LiDAR, which are built into newer models of iPads and iPhones. LiDAR is great at finding flat surfaces - both position and orientation! Our solution was to alter the April Tag detection to add the step of flattening it to a wall through raycasting. Since the wall orientation from the LiDAR was very accurate, this largely solved our outlier problem and made for much, much better maps. By the end of the summer, my partner and I had taken Invisible Map from wishful thinking to a solid, proof-of-concept demo!

### Future Work

One final issue we tried to tackle that summer was path optimization. While we essentially had a trail of "breadcrumbs" around a building, it was often difficult to detect where this trail overlapped. Without detecting overlap, users would have to exactly follow the path that the map creator walked, which often results in long and roundabout paths. The original solution was to find a place where two pairs of adjacent breadcrumbs crossed paths, and add an extra breadcrumb there. This, however, required the paths to physically overlap, but this was not always the case. Say the map creator walked down a hallway, turned around, and walked down the other side of the hallway before turning into a side path. If Invisible Map wanted to navigate a user down this side path, through the intersection technique, it has no way of knowing that the user does not have to walk all the way down the hallway before turning, since there are not any intersections between the two paths.

We instead worked on an algorithm that would determine if two points in space were connected by a floor (with no walls in between). This algorithm also relied on LiDAR surface detection to find the floor and any walls. Given two points, it would raycast from one to another, looking for any walls inbetween. If the walls were found, then the points are not connected. Otherwise, they are. The entire algorithm was slightly more complicated, such as checking that the distance between the points was close enough for accurate readings, but the core of it is the raycast.

While we did not have time to fully implement this floor detection into Invisible Map proper, we set up a demo app and algorithm for future OCCaM researchers to add themselves.
